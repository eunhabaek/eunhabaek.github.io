MySQL 데이터 S3로 수집
================

파이썬 프로젝트를 위한 환경설정
-----------------

### 1) 가상환경 생성

    python -m venv venv
    venv\Scripts\activate.bat

### 2) 환경설정

*   필요 패키지 설치
    
        pip install configparser 
    

*   접속 정보 저장을 위한 파일 생성
    
        [mysql_config]
        hostname = localhost
        port = 3306
        username = root
        password = wnddkd
        database = mysql
    
    *   config 파일 만드는 이유는 빌드 자동화

MySQL 설치하고 샘플 데이터 생성
--------------------

### 1) 도커로 mysql 실행

    docker run --name mysql-container -e MYSQL_ROOT_PASSWORD=wnddkd -d -p 3306:3306 mysql:latest

### 2) Dbeaver 실핼

[![](MySQL%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20S3%E1%84%85%E1%85%A9%20%E1%84%89%E1%85%AE%E1%84%8C%E1%85%B5%E1%86%B8%20465c0d9d2c5c476282b048ecdf9e634d/Untitled.png)](MySQL%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20S3%E1%84%85%E1%85%A9%20%E1%84%89%E1%85%AE%E1%84%8C%E1%85%B5%E1%86%B8%20465c0d9d2c5c476282b048ecdf9e634d/Untitled.png)

### 3) 샘플 데이터 생성

    CREATE TABLE Orders (
    OrderId int,
    OrderStatus varchar(30),
    LastUpdated timestamp
    );
    
    INSERT INTO Orders VALUES(1,'Backordered', '2020-06-01 12:00:00');

CSV에 DB 내용 저장
-------------

### 1) 패키지 설지

    pip install pymysql

### 2) [main.p](http://main.py)y에서 데이터베이스 읽어와서 csv에 저장

    import pymysql
    import csv
    import configparser
    
    #환경 설정 파일의 내용 가져오기
    parser = configparser.ConfigParser()
    parser.read("pipeline.conf")
    
    #환경 설정 파일의 내용을 이용해서 데이터베이스 접속 정보 만들기
    hostname = parser.get("mysql_config", "hostname")
    port = parser.get("mysql_config", "port")
    username = parser.get("mysql_config", "username")
    dbname = parser.get("mysql_config", "database")
    password = parser.get("mysql_config", "password")
    
    #데이터베이스 연결
    conn = pymysql.connect(host=hostname,
    user=username,
    password=password,
    db=dbname,
    port=int(port))
    
    if conn is None:
        print("연결 에러 MySQL database")
    
    #데이터베이스에 연결이 된 경우만 쿼리를 실행해서 csc 파일에 저장
    else:
        print("MySQL database 연결 성공!")
        m_query = "SELECT * FROM Orders;"
    
        #S3에 저장할 파일 이름
        local_filename = "order_extract.csv"
        
        #데이터 베이스에 쿼리 수행할 객체 생성
        m_cursor = conn.cursor()
    
        #쿼리 수행
        m_cursor.execute(m_query)
        
        #python에서는 관계형 데이터 베이스에 질의하면 tuple의 tuple 결과 리턴
        results = m_cursor.fetchall()
    
        #데이터베이스에서 읽은 내용을 csv 파일에 기록
        with open(local_filename, 'w') as fp:
            csv_w = csv.writer(fp, delimiter='|')
            csv_w.writerows(results)
            m_cursor.close()
    conn.close()

### 3) [main.py](http://main.py) 실행

    python main.py

*   생성된 csv 결과 확인
    
    [![](MySQL%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20S3%E1%84%85%E1%85%A9%20%E1%84%89%E1%85%AE%E1%84%8C%E1%85%B5%E1%86%B8%20465c0d9d2c5c476282b048ecdf9e634d/Untitled%201.png)](MySQL%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20S3%E1%84%85%E1%85%A9%20%E1%84%89%E1%85%AE%E1%84%8C%E1%85%B5%E1%86%B8%20465c0d9d2c5c476282b048ecdf9e634d/Untitled%201.png)
    

*   이 실행 부분을 cron OR git action으로 자동화 기능 개선 가능

### 4) conf 파일에 s3 버킷 설정

    [aws_boto_credentials]
    access_key = AKIAZ6BCJVVQHSCDCG63
    secret_key = **
    bucket_name = mysqlextract
    account_id = **

### 5) boto3 패키지 설치

    pip install boto3

### 6) aws 버킷 권한 설정

    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "PublicListGet",
                "Effect": "Allow",
                "Principal": "*",
                "Action": [
                    "s3:List*",
                    "s3:Get*",
                    "s3:Put*",
                    "s3:Delete*"
                ],
                "Resource": [
                    "arn:aws:s3:::eunhabucket",
                    "arn:aws:s3:::eunhabucket/*"
                ]
            }
        ]
    	}

### 7) [main.py](http://main.py) 수정 후 재실행

    import pymysql
    import csv
    import configparser
    import boto3 
    from botocore.exceptions import ClientError
    
    #환경 설정 파일의 내용 가져오기
    parser = configparser.ConfigParser()
    parser.read("pipeline.conf")
    
    #환경 설정 파일의 내용을 이용해서 데이터베이스 접속 정보 만들기
    hostname = parser.get("mysql_config", "hostname")
    port = parser.get("mysql_config", "port")
    username = parser.get("mysql_config", "username")
    dbname = parser.get("mysql_config", "database")
    password = parser.get("mysql_config", "password")
    
    #데이터베이스 연결
    conn = pymysql.connect(host=hostname,
    user=username,
    password=password,
    db=dbname,
    port=int(port))
    
    if conn is None:
        print("연결 에러 MySQL database")
    
    #데이터베이스에 연결이 된 경우만 쿼리를 실행해서 csc 파일에 저장
    else:
        print("MySQL database 연결 성공!")
        m_query = "SELECT * FROM Orders;"
    
        #S3에 저장할 파일 이름
        local_filename = "order_extract.csv"
        
        #데이터 베이스에 쿼리 수행할 객체 생성
        m_cursor = conn.cursor()
    
        #쿼리 수행
        m_cursor.execute(m_query)
        
        #python에서는 관계형 데이터 베이스에 질의하면 tuple의 tuple 결과 리턴
        results = m_cursor.fetchall()
    
        #데이터베이스에서 읽은 내용을 csv 파일에 기록
        with open(local_filename, 'w') as fp:
            csv_w = csv.writer(fp, delimiter='|')
            csv_w.writerows(results)
            m_cursor.close()
            fp.close()
    
            #S3 버킷 설정
            access_key = parser.get("aws_boto_credentials", "access_key")
            secret_key = parser.get("aws_boto_credentials", "secret_key")
            bucket_name = parser.get("aws_boto_credentials", "bucket_name")
    
            s3 = boto3.client('s3', aws_access_key_id=access_key,
            aws_secret_access_key=secret_key)
            s3_file = local_filename
            try:
                response = s3.upload_file(local_filename, bucket_name, s3_file)
            except ClientError as e:
                print(e)
    
    
    
    conn.close()

*   아래와 같이 S3에 csb 파일 업로드 확인

[![](MySQL%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20S3%E1%84%85%E1%85%A9%20%E1%84%89%E1%85%AE%E1%84%8C%E1%85%B5%E1%86%B8%20465c0d9d2c5c476282b048ecdf9e634d/Untitled%202.png)](MySQL%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20S3%E1%84%85%E1%85%A9%20%E1%84%89%E1%85%AE%E1%84%8C%E1%85%B5%E1%86%B8%20465c0d9d2c5c476282b048ecdf9e634d/Untitled%202.png)

전체수집의 한계점
---------

*   항상 마지막 스냅샷 결과만 저장함

*   별도로 작업 내역을 기록해야 함

증분 백업을 위한 [main.py](http://main.py) 수정
--------------------------------------

    import pymysql
    import csv
    import configparser
    import boto3
    from botocore.exceptions import ClientError
    
    #환경 설정 파일의 내용 가져오기
    parser = configparser.ConfigParser()
    parser.read("pipeline.conf")
    
    #환경 설정 파일의 내용을 이용해서 데이터베이스 접속 정보 만들기
    hostname = parser.get("mysql_config", "hostname")
    port = parser.get("mysql_config", "port")
    username = parser.get("mysql_config", "username")
    dbname = parser.get("mysql_config", "database")
    password = parser.get("mysql_config", "password")
    
    #S3 버킷 설정
    access_key = parser.get("aws_boto_credentials", "access_key")
    secret_key = parser.get("aws_boto_credentials", "secret_key")
    bucket_name = parser.get("aws_boto_credentials", "bucket_name")
    s3 = boto3.client('s3', aws_access_key_id=access_key,
    aws_secret_access_key=secret_key)
    
    m_query = None
    with open('lastread.csv', 'wb') as f:
        try:
            s3.download_fileobj(bucket_name, 'lastread.csv', f)
        except ClientError as e:
            pass
    with open('order_extract.csv', 'wb') as f:
        try:
            s3.download_fileobj(bucket_name, 'order_extract.csv"', f)
        except ClientError as e:
            pass
    
    with open('lastread.csv', 'rb') as f:
        x = f.readline()
        if len(x) > 0:
            m_query = "SELECT * FROM Orders WHERE LastUpdated > '" +x.decode('utf-8') + "' ORDER BY LastUpdated;"
        else:
            m_query = "SELECT * FROM Orders ORDER BY LastUpdated;"
    
    #데이터베이스 연결
    conn = pymysql.connect(host=hostname,
    user=username,
    password=password,
    db=dbname,
    port=int(port))
    
    if conn is None:
        print("연결 에러 MySQL database")
    #데이터베이스에 연결이 된 경우만 쿼리를 실행해서 csv 파일에 저장
    else:
        print("MySQL database 연결 성공!")
    
    #S3에 저장할 파일 이름
    local_filename = "order_extract.csv"
    m_cursor = conn.cursor()
    m_cursor.execute(m_query)
    results = m_cursor.fetchall()
    
    with open(local_filename, 'a') as fp:
        csv_w = csv.writer(fp, delimiter='|')
        csv_w.writerows(results)
        with open('lastread.csv', 'w') as fp1:
            fp1.write(str(results[-1][-1]))
            print(str(results[-1][-1]))
            fp1.close()
        m_cursor.close()
        fp.close()
        s3_file = local_filename
        try:
            response = s3.upload_file(local_filename, bucket_name, s3_file)
            s3.upload_file('lastread.csv', bucket_name, 'lastread.csv')
        except ClientError as e:
            print(e)
        conn.close()

*   이전 기록을 불러와서 새로 바뀐 내용만 저장 가능